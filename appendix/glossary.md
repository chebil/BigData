# Glossary of Big Data Terms

## A

**Algorithm**: Step-by-step procedure for calculations

**ARIMA**: AutoRegressive Integrated Moving Average - time series model

**Association Rules**: Pattern mining technique for discovering relationships

## B

**Batch Processing**: Processing large volumes of data at once

**Big Data**: Datasets too large for traditional processing

**Bias**: Systematic error in model predictions

## C

**Classification**: Predicting categorical outcomes

**Clustering**: Grouping similar data points

**Cross-Validation**: Model validation technique

## D

**Data Lake**: Centralized repository for raw data

**Data Warehouse**: Structured data storage for analytics

**DBSCAN**: Density-Based Spatial Clustering of Applications with Noise

## E

**EDA**: Exploratory Data Analysis

**Ensemble**: Combining multiple models

**ETL**: Extract, Transform, Load - data pipeline process

## F

**Feature Engineering**: Creating new features from existing data

**F1-Score**: Harmonic mean of precision and recall

## H

**Hadoop**: Distributed storage and processing framework

**HDFS**: Hadoop Distributed File System

**Hyperparameter**: Model configuration parameter

## K

**K-Means**: Centroid-based clustering algorithm

**KNN**: K-Nearest Neighbors algorithm

## M

**MapReduce**: Programming model for distributed computing

**ML**: Machine Learning

**Model**: Mathematical representation of data patterns

## N

**NLP**: Natural Language Processing

**Normalization**: Scaling data to standard range

## O

**Overfitting**: Model too complex, poor generalization

## P

**Precision**: True positives / (True positives + False positives)

**PySpark**: Python API for Apache Spark

## R

**Recall**: True positives / (True positives + False negatives)

**Regression**: Predicting continuous outcomes

**RFM**: Recency, Frequency, Monetary analysis

## S

**Spark**: Distributed computing framework

**Supervised Learning**: Learning from labeled data

## T

**TF-IDF**: Term Frequency-Inverse Document Frequency

**Training Set**: Data used to train model

## U

**Unsupervised Learning**: Learning from unlabeled data

## V

**Validation Set**: Data used to tune model

**Variance**: Model sensitivity to training data variations

**Volume, Velocity, Variety**: The 3 V's of Big Data
