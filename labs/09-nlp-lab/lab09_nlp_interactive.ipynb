{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 9: Text Analytics & Sentiment Analysis\n",
    "## Interactive Notebook\n",
    "\n",
    "### Learning Objectives\n",
    "1. Preprocess text data\n",
    "2. Implement TF-IDF vectorization\n",
    "3. Build sentiment classifiers\n",
    "4. Create word clouds\n",
    "5. Evaluate NLP models\n",
    "\n",
    "**Time:** 4-5 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "print('‚úÖ Ready!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Part 1: Create Sample Reviews"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample movie reviews\n",
    "reviews = {\n",
    "    'text': [\n",
    "        'This movie was absolutely fantastic! Best film ever.',\n",
    "        'Terrible movie. Complete waste of time.',\n",
    "        'Amazing performance by the actors. Highly recommend!',\n",
    "        'Boring plot and awful acting.',\n",
    "        'Brilliant storytelling and great cinematography.',\n",
    "        'Worst movie I have ever seen. Absolutely horrible.'\n",
    "    ],\n",
    "    'sentiment': ['positive', 'negative', 'positive', 'negative', 'positive', 'negative']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(reviews)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["### üìù Task: Text Preprocessing"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # TODO: Implement preprocessing\n",
    "    # 1. Lowercase\n",
    "    text = # YOUR CODE\n",
    "    \n",
    "    # 2. Remove special characters\n",
    "    text = # YOUR CODE\n",
    "    \n",
    "    # 3. Tokenize\n",
    "    tokens = # YOUR CODE\n",
    "    \n",
    "    # 4. Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = # YOUR CODE\n",
    "    \n",
    "    # 5. Lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = # YOUR CODE\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['cleaned_text'] = df['text'].apply(preprocess_text)\n",
    "print(df[['text', 'cleaned_text']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Part 2: TF-IDF Vectorization"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create TF-IDF vectors\n",
    "vectorizer = TfidfVectorizer(max_features=100)\n",
    "X = # YOUR CODE\n",
    "y = # YOUR CODE\n",
    "\n",
    "print(f'TF-IDF matrix shape: {X.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Part 3: Build Sentiment Classifier"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train Naive Bayes classifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "nb = MultinomialNB()\n",
    "# YOUR CODE: Fit and evaluate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Part 4: Word Cloud"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create word clouds for positive and negative reviews\n",
    "positive_text = ' '.join(df[df['sentiment'] == 'positive']['cleaned_text'])\n",
    "negative_text = ' '.join(df[df['sentiment'] == 'negative']['cleaned_text'])\n",
    "\n",
    "# Generate word clouds\n",
    "# YOUR CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üìù Summary\n",
    "‚úÖ Preprocessed text\n",
    "‚úÖ Created TF-IDF vectors\n",
    "‚úÖ Built sentiment classifier\n",
    "‚úÖ Generated word clouds\n",
    "**Amazing NLP work! üí¨üéâ**"
   ]
  }
 ],
 "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}},
 "nbformat": 4,
 "nbformat_minor": 4
}