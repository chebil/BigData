{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Classification - Fraud Detection\n",
    "## Interactive Notebook\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "1. Handle imbalanced datasets\n",
    "2. Implement multiple classification algorithms\n",
    "3. Evaluate models with ROC-AUC\n",
    "4. Optimize for precision vs recall\n",
    "5. Deploy a fraud detection system\n",
    "\n",
    "**Estimated Time:** 4-5 hours\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                             roc_auc_score, roc_curve, precision_recall_curve,\n",
    "                             accuracy_score, precision_score, recall_score, f1_score)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "print('‚úÖ Libraries loaded successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load and Explore Data\n",
    "\n",
    "We'll create a synthetic credit card fraud dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic fraud detection data\n",
    "np.random.seed(42)\n",
    "\n",
    "n_samples = 10000\n",
    "fraud_ratio = 0.02  # 2% fraud\n",
    "\n",
    "# Normal transactions\n",
    "n_normal = int(n_samples * (1 - fraud_ratio))\n",
    "normal_amount = np.random.normal(100, 50, n_normal)\n",
    "normal_time = np.random.uniform(0, 24, n_normal)\n",
    "normal_distance = np.random.normal(10, 5, n_normal)\n",
    "\n",
    "# Fraudulent transactions (different patterns)\n",
    "n_fraud = int(n_samples * fraud_ratio)\n",
    "fraud_amount = np.random.normal(500, 200, n_fraud)\n",
    "fraud_time = np.random.uniform(0, 6, n_fraud)  # Late night\n",
    "fraud_distance = np.random.normal(100, 50, n_fraud)  # Far from home\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Amount': np.concatenate([normal_amount, fraud_amount]),\n",
    "    'Time': np.concatenate([normal_time, fraud_time]),\n",
    "    'Distance': np.concatenate([normal_distance, fraud_distance]),\n",
    "    'NumTransactions': np.concatenate([\n",
    "        np.random.randint(1, 10, n_normal),\n",
    "        np.random.randint(1, 3, n_fraud)\n",
    "    ]),\n",
    "    'IsFraud': np.concatenate([np.zeros(n_normal), np.ones(n_fraud)])\n",
    "})\n",
    "\n",
    "# Shuffle\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f'Dataset created: {len(df)} transactions')\n",
    "print(f'\\nClass distribution:')\n",
    "print(df['IsFraud'].value_counts())\n",
    "print(f'\\nFraud percentage: {df[\"IsFraud\"].mean()*100:.2f}%')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù Task 1: Explore Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a bar plot showing class distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "# YOUR CODE HERE\n",
    "\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Class Distribution (Imbalanced)')\n",
    "plt.show()\n",
    "\n",
    "# TODO: Calculate imbalance ratio\n",
    "imbalance_ratio = # YOUR CODE HERE\n",
    "print(f'Imbalance ratio: 1:{imbalance_ratio:.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "plt.figure(figsize=(10, 6))\n",
    "class_counts = df['IsFraud'].value_counts()\n",
    "plt.bar(['Normal', 'Fraud'], class_counts, color=['green', 'red'], alpha=0.7, edgecolor='black')\n",
    "for i, v in enumerate(class_counts):\n",
    "    plt.text(i, v + 50, str(v), ha='center', fontweight='bold')\n",
    "plt.xlabel('Class', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.title('Class Distribution (Highly Imbalanced)', fontsize=14, fontweight='bold')\n",
    "plt.grid(alpha=0.3, axis='y')\n",
    "plt.show()\n",
    "\n",
    "n_normal = (df['IsFraud'] == 0).sum()\n",
    "n_fraud = (df['IsFraud'] == 1).sum()\n",
    "imbalance_ratio = n_normal / n_fraud\n",
    "print(f'‚ö†Ô∏è Imbalance ratio: 1:{imbalance_ratio:.0f}')\n",
    "print(f'For every 1 fraud case, there are {imbalance_ratio:.0f} normal cases')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù Task 2: Compare Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create box plots for each feature, separated by class\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "features = ['Amount', 'Time', 'Distance', 'NumTransactions']\n",
    "\n",
    "for idx, feature in enumerate(features):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    # YOUR CODE HERE: Create box plot\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Data Preparation\n",
    "\n",
    "### Split and Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = df.drop('IsFraud', axis=1)\n",
    "y = df['IsFraud']\n",
    "\n",
    "# TODO: Split data (80/20)\n",
    "X_train, X_test, y_train, y_test = # YOUR CODE HERE\n",
    "\n",
    "# TODO: Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = # YOUR CODE HERE\n",
    "X_test_scaled = # YOUR CODE HERE\n",
    "\n",
    "print(f'Training set: {X_train.shape[0]} samples')\n",
    "print(f'Test set: {X_test.shape[0]} samples')\n",
    "print(f'\\nTraining class distribution:')\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Baseline Model (Without Handling Imbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train Logistic Regression\n",
    "lr_baseline = LogisticRegression(random_state=42)\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# TODO: Make predictions\n",
    "y_pred_baseline = # YOUR CODE HERE\n",
    "\n",
    "# TODO: Print classification report\n",
    "print('Baseline Model (No Rebalancing):')\n",
    "print('=' * 60)\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ö†Ô∏è Notice the Problem!\n",
    "\n",
    "The model likely has:\n",
    "- High accuracy (but misleading!)\n",
    "- Low recall for fraud class\n",
    "- Poor performance on minority class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Handle Imbalance with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = # YOUR CODE HERE\n",
    "\n",
    "print('After SMOTE:')\n",
    "print(f'Training samples: {len(X_train_balanced)}')\n",
    "print(f'Class distribution:')\n",
    "print(pd.Series(y_train_balanced).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Train Multiple Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=10),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# TODO: Train each model and store predictions\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # YOUR CODE HERE: Fit model\n",
    "    \n",
    "    # YOUR CODE HERE: Predict\n",
    "    \n",
    "    # YOUR CODE HERE: Calculate metrics\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'predictions': None,  # YOUR CODE\n",
    "        'accuracy': None,  # YOUR CODE\n",
    "        'precision': None,  # YOUR CODE\n",
    "        'recall': None,  # YOUR CODE\n",
    "        'f1': None,  # YOUR CODE\n",
    "        'roc_auc': None  # YOUR CODE\n",
    "    }\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df[['accuracy', 'precision', 'recall', 'f1', 'roc_auc']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: ROC Curve Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot ROC curves for all models\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for name, result in results.items():\n",
    "    # YOUR CODE HERE: Get probability predictions\n",
    "    # YOUR CODE HERE: Calculate ROC curve\n",
    "    # YOUR CODE HERE: Plot curve\n",
    "    pass\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves - Model Comparison')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üéØ Practice Questions\n",
    "\n",
    "1. Which model performs best for fraud detection? Why?\n",
    "2. What is more important for fraud detection: precision or recall?\n",
    "3. How does SMOTE help with imbalanced data?\n",
    "4. What other techniques could handle class imbalance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üìù Summary\n",
    "\n",
    "‚úÖ Identified and handled class imbalance\n",
    "‚úÖ Implemented SMOTE for oversampling\n",
    "‚úÖ Trained multiple classifiers\n",
    "‚úÖ Evaluated with appropriate metrics\n",
    "‚úÖ Analyzed ROC curves\n",
    "\n",
    "**Great work on fraud detection! üéâ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}